{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fe3efb-2ee5-4974-8850-2bec73c242e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svm\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m47\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen_data\u001b[39m(sample_size, noise, decision_boundary):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(47)\n",
    "\n",
    "def gen_data(sample_size, noise, decision_boundary):\n",
    "  X = []\n",
    "  y = []\n",
    "  m = []\n",
    "  for i in range(sample_size):\n",
    "    x1 = np.random.uniform(-2, 2)\n",
    "    x2 = np.random.uniform(-2, 2)\n",
    "    noise_val = np.random.uniform(0,1)\n",
    "    X.append([x1, x2])\n",
    "    if (x1 > decision_boundary[0]) != (x2 > decision_boundary[1]):\n",
    "      if noise_val > noise:\n",
    "        y.append(1)\n",
    "        m.append('+')\n",
    "      else:\n",
    "        y.append(0)\n",
    "        m.append('o')\n",
    "    else:\n",
    "      if noise_val > noise:\n",
    "        y.append(0)\n",
    "        m.append('o')\n",
    "      else:\n",
    "        y.append(1)\n",
    "        m.append('+')\n",
    "  return np.array(X), np.array(y), m\n",
    "\n",
    "# DATASET 1: big (1000 samples), with low noise (1% of samples are wrong)\n",
    "# and decision boudary in the middle of interval from which data is generated\n",
    "X1, y1, m1 = gen_data(1000, 0.01, [0,0])\n",
    "X1_t, y1_t, m1_t = gen_data(100, 0.01, [0,0])\n",
    "\n",
    "# DATASET 2: small (100 samples), noisy (25% of samples are wrong)\n",
    "# and decision boudary in the middle of x-axis and 3/4 of y-axis\n",
    "# of interval from which data is generated\n",
    "X2, y2, m2 = gen_data(100, 0.25, [0,1])\n",
    "X2_t, y2_t, m2_t = gen_data(100, 0.25, [0,1])\n",
    "\n",
    "# DATASET 3: medium (300 saples), medium noise (10% of samples are wrong)\n",
    "# and decision boudary in the middle of x-axis and 3/4 of y-axis\n",
    "# of interval from which data is generated\n",
    "X3, y3, m3 = gen_data(300, 0.1, [1,1])\n",
    "X3_t, y3_t, m3_t = gen_data(100, 0.1, [1,1])\n",
    "\n",
    "X, y, m = [X1, X2, X3], [y1, y2, y3], [m1, m2, m3]\n",
    "X_t, y_t, m_t = [X1_t, X2_t, X3_t], [y1_t, y2_t, y3_t], [m1_t, m2_t, m3_t]\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "x_min, x_max = X[0][:, 0].min() - 1, X[0][:, 0].max() + 1\n",
    "y_min, y_max = X[0][:, 1].min() - 1, X[0][:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "for i in range(3):\n",
    "  print(\"dataset\", i)\n",
    "  fig, ax = plt.subplots(3,3)\n",
    "  for a, c in enumerate([0.1, 1, 10]):\n",
    "    for b, g in enumerate([0.1, 1, 10]):\n",
    "\n",
    "      # we create an instance of SVM and fit out data.\n",
    "      clf = svm.SVC(kernel='rbf', gamma=g, C=c)\n",
    "      clf.fit(X[i], y[i])\n",
    "      Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "      # Put the result into a color plot\n",
    "      Z = Z.reshape(xx.shape)\n",
    "      ax[a,b].pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "      # Plot also the training points\n",
    "      ax[a,b].scatter(X[i][:, 0], X[i][:, 1], c=(3*y[i]+1), s=1)\n",
    "      ax[a,b].axis('tight')\n",
    "      if a == 2:\n",
    "        ax[a,b].set_xlabel(\"gamma={}\".format(g))\n",
    "      if b == 0:\n",
    "        ax[a,b].set_ylabel(\"C={}\".format(c))\n",
    "  fig.savefig(\"dataset_{}_diff_c_gamma.png\".format(i+1))\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  tested_vals = 2.**np.array(list(range(-5, 15)))\n",
    "\n",
    "  s_train = []\n",
    "  s_test = []\n",
    "  for j in tested_vals:\n",
    "    clf = svm.SVC(kernel='rbf', gamma=j, C=1)\n",
    "    clf.fit(X[i], y[i])\n",
    "    #print(clf.score(X[i], y[i]))\n",
    "    s_train.append(clf.score(X[i], y[i]))\n",
    "    s_test.append(clf.score(X_t[i], y_t[i]))\n",
    "\n",
    "  plt.plot(tested_vals, s_train)\n",
    "  plt.ylim([0,1.1])\n",
    "  plt.xscale(\"log\")\n",
    "  plt.xlabel(\"gamma\")\n",
    "  plt.ylabel(\"training score\")\n",
    "  plt.savefig(\"dataset_{}_train_gamma_scores.png\".format(i+1))\n",
    "  plt.show()\n",
    "\n",
    "  plt.plot(tested_vals, s_test)\n",
    "  plt.ylim([0,1.1])\n",
    "  plt.xscale(\"log\")\n",
    "  plt.xlabel(\"gamma\")\n",
    "  plt.ylabel(\"validation score\")\n",
    "  plt.savefig(\"dataset_{}_validation_gamma_scores.png\".format(i+1))\n",
    "  plt.show()\n",
    "\n",
    "  s_train = []\n",
    "  s_test = []\n",
    "  for j in tested_vals:\n",
    "    clf = svm.SVC(kernel='rbf', gamma=1, C=j)\n",
    "    clf.fit(X[i], y[i])\n",
    "    #print(clf.score(X[i], y[i]))\n",
    "    s_train.append(clf.score(X[i], y[i]))\n",
    "    s_test.append(clf.score(X_t[i], y_t[i]))\n",
    "\n",
    "  plt.plot(tested_vals, s_train)\n",
    "  plt.ylim([0,1.1])\n",
    "  plt.xscale(\"log\")\n",
    "  plt.xlabel(\"C\")\n",
    "  plt.ylabel(\"training score\")\n",
    "  plt.savefig(\"dataset_{}_train_C_scores.png\".format(i+1))\n",
    "  plt.show()\n",
    "\n",
    "  plt.plot(tested_vals, s_test)\n",
    "  plt.ylim([0,1.1])\n",
    "  plt.xscale(\"log\")\n",
    "  plt.xlabel(\"C\")\n",
    "  plt.ylabel(\"validation score\")\n",
    "  plt.savefig(\"dataset_{}_validation_C_scores.png\".format(i+1))\n",
    "  plt.show()\n",
    "\n",
    "  scores_train = np.zeros([len(tested_vals),len(tested_vals)])\n",
    "  scores_test = np.zeros([len(tested_vals),len(tested_vals)])\n",
    "  for k, u in enumerate(tested_vals):\n",
    "    for j, v in enumerate(tested_vals):\n",
    "      clf = svm.SVC(kernel='rbf', gamma=u, C=v)\n",
    "      clf.fit(X[i], y[i])\n",
    "      scores_train[k, j] = clf.score(X[i], y[i])\n",
    "      scores_test[k, j] = clf.score(X_t[i], y_t[i])\n",
    "\n",
    "\n",
    "  sns.heatmap(scores_train, vmin=0, vmax=1, xticklabels=tested_vals, yticklabels=tested_vals, cmap='autumn')\n",
    "  plt.xlabel(\"C\")\n",
    "  plt.ylabel(\"gamma\")\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(\"dataset_{}_train_heatmap_scores.png\".format(i+1))\n",
    "  plt.show()\n",
    "\n",
    "  sns.heatmap(scores_test, vmin=0, vmax=1, xticklabels=tested_vals, yticklabels=tested_vals, cmap='autumn')\n",
    "  plt.xlabel(\"C\")\n",
    "  plt.ylabel(\"gamma\")\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(\"dataset_{}_validation_heatmap_scores.png\".format(i+1))\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b232182-2b80-4b0b-8af7-372a69033668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
